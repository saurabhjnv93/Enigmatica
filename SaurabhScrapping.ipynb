{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/Desktop/Enigmatica /chatbot/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from PDFTextProcessor import PDFTextProcessor\n",
    "from AnsweringClass import AnsweringClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AnsweringClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction completed. Saved to output_text_russell.txt\n",
      "Text cleaning completed. Saved to cleaned_text_russell.txt\n",
      "DataFrame saved to paragraphs.csv\n"
     ]
    }
   ],
   "source": [
    "processor = PDFTextProcessor(\n",
    "    pdf_path=\"../books/AI_Russell_Norvig.pdf\",\n",
    "    output_txt_path=\"output_text_russell.txt\",\n",
    "    cleaned_txt_path=\"cleaned_text_russell.txt\"\n",
    ")\n",
    "\n",
    "# Step 1: Extract and clean text from the PDF\n",
    "processor.extract_text()\n",
    "\n",
    "# Step 2: Further clean the raw extracted text\n",
    "processor.clean_text_file()\n",
    "\n",
    "# Step 3: Process the cleaned text into paragraphs and save as CSV\n",
    "df = processor.process_text_to_dataframe(\"cleaned_text_russell.txt\", output_csv_path=\"paragraphs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"] = df[\"paragraph\"].apply(lambda x: a.get_sentence_embedding(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"embedding\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =(a.get_top_matches(       \"What is the difference between forward chaining and backward chaining in logical reasoning?\",df,embedding_column=\"embedding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It also means that backward chaining (unlike forward chaining) suffers from problems with repeated states and incompleteness. We will discuss these problems and some potential solutions, but ﬁrst we show how backward chaining is used in logic programming systems.Chapter ﬁrst,rest ←FIRST(goals), REST(goals) Proof tree constructed by backward chaining to prove that West is a criminal.\n",
      "cated compiler technology to provide very fast inference. Backward chaining suffers from redundant inferences and inﬁnite loops; these can be alleviated by memoization. and negation as failure. These make Prolog a more practical programming language, but bring it further from pure logic. order logic, using knowledge bases in conjunctive normal form.\n",
      "The resolution rule yields a complete inference algorithm for knowledge bases that are expressed in conjunctive normal form. Forward chaining and backward chaining are very natural reasoning algorithms for knowledge bases in Horn form. rithms are sound but not complete. • Logical state estimation involves maintaining a logical sentence that describes the set of possible states consistent with the observation history.\n",
      "This is characteristic of resolution on Horn clause knowledge bases. In fact, the clauses along the main spine positive literal uniﬁed with the leftmost literal of the “current” clause on the spine; this is exactly what happens in backward chaining. Thus, backward chaining is just a special case of resolution with a particular control strategy to decide which resolution to perform next.\n",
      "as a theorem prover for deﬁnite clauses—even for Datalog programs, as this example shows— because, for some knowledge bases, it fails to prove sentences that are entailed. Notice that forward chaining does not suffer from this problem: once path(a,b), path(b,c), and path(a,c) are inferred, forward chaining halts.\n"
     ]
    }
   ],
   "source": [
    "for i in b:\n",
    "    print(i[0].replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial knowledge base contains the atemporal axioms—those that don’t depend time step, the new percept sentence is added along with all the axioms that depend on t, suchAgents Based on Propositional Logic for future time steps.) Then, the agent uses logical inference, by ASKing questions of the knowledge base, to work out which squares are safe and which have yet to be visited.\n"
     ]
    }
   ],
   "source": [
    "text = \"The initial knowledge base contains the atemporal axioms—those that don’t depend\\ntime step, the new percept sentence is added along with all the axioms that depend on t, suchAgents Based on Propositional Logic\\nfor future time steps.) Then, the agent uses logical inference, by ASKing questions of the\\nknowledge base, to work out which squares are safe and which have yet to be visited.\"\n",
    "print(text.replace(\"\\n\",\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
