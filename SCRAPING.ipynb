{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction and cleaning completed.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean extracted text to exclude lines that resemble mathematical expressions,\n",
    "    index entries, or table of contents entries (e.g., lines with ellipses or numbers).dd\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to identify unwanted lines\n",
    "    unwanted_patterns = [\n",
    "        r\"\\.\\.\\.+\\s*\\d+\",            # Lines with ellipses followed by numbers\n",
    "        r\"^\\d+\\.\\d+\\s\",              # Lines starting with a decimal number (e.g., \"1.1 \")\n",
    "        r\"\\b\\d+\\b\",                  # Lines containing isolated numbers (page numbers, indexes)\n",
    "        r\"[A-Za-z0-9]+[\\^\\+\\-*/=<>]\", # Lines with mathematical operators\n",
    "        r\"[A-Za-z0-9]+\\s*[∈∀∃∅⊆∪∩≈∑∏∫θμϵλϕδΩ→≤≥]\", # Lines with symbols commonly in math\n",
    "        r\"[θμϵδ]+\",                  # Greek symbols or Greek-like variables\n",
    "        r\"[<>≤≥=]{2,}\",              # Comparison operators often found in math expressions\n",
    "        r\"^\\d+$\",                    # Lines with only numbers\n",
    "    ]\n",
    "    \n",
    "    # Combine all patterns into one\n",
    "    combined_pattern = re.compile(\"|\".join(unwanted_patterns))\n",
    "    \n",
    "    # Split the text into lines, filter them, and rejoin\n",
    "    filtered_lines = [\n",
    "        line for line in text.splitlines()\n",
    "        if not combined_pattern.search(line)\n",
    "    ]\n",
    "    \n",
    "    return \"\\n\".join(filtered_lines)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF, clean it using clean_text function, and save it to a text file.\n",
    "    \"\"\"\n",
    "    # Open the PDF file\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "\n",
    "    # Iterate through pages and extract text\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_num]\n",
    "        full_text += page.get_text()\n",
    "\n",
    "    # Clean the extracted text\n",
    "    cleaned_text = clean_text(full_text)\n",
    "    \n",
    "    # Save cleaned text to output file\n",
    "    with open(output_txt_path, \"w\") as txt_file:\n",
    "        txt_file.write(cleaned_text)\n",
    "\n",
    "    # Close the PDF\n",
    "    pdf_document.close()\n",
    "\n",
    "# Usage\n",
    "pdf_path = \"../INIGMETICA/AI_Russell_Norvig.pdf\"         # Replace with your PDF file path\n",
    "output_txt_path = \"output_text_russell.txt\"    # Replace with desired output text file path\n",
    "extract_text_from_pdf(pdf_path, output_txt_path)\n",
    "\n",
    "print(\"Text extraction and cleaning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning completed.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text_file(input_txt_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Reads a text file, removes lines with specific matrix, summation, or symbol patterns,\n",
    "    and removes lines with fewer than 20 characters. Writes the cleaned content to a new file.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to identify unwanted lines\n",
    "    unwanted_patterns = [\n",
    "        r\"=\\s*m\\s*X\\s*xi\\s*x⊤\\s*i\",  # Pattern for \"= m X xi x⊤ i\"\n",
    "        r\"b\\s*=\\s*m\\s*X\\s*yixi\",     # Pattern for \"b = m X yixi\"\n",
    "        r\"A\\s*=\\s*\\(.*\\)\",           # Matrix-like form pattern\n",
    "        r\"b\\s*=\\s*\\(\"                # Pattern for matrix b with open parentheses\n",
    "    ]\n",
    "    \n",
    "    # Combine all patterns into one\n",
    "    combined_pattern = re.compile(\"|\".join(unwanted_patterns))\n",
    "    \n",
    "    with open(input_txt_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Filter lines by patterns and length\n",
    "    filtered_lines = [\n",
    "        line for line in lines\n",
    "        if not combined_pattern.search(line) and len(line.strip()) >= 20\n",
    "    ]\n",
    "\n",
    "    # Write the cleaned lines to the output file\n",
    "    with open(output_txt_path, \"w\") as file:\n",
    "        file.writelines(filtered_lines)\n",
    "\n",
    "# Usage\n",
    "input_txt_path = \"output_text_russell.txt\"      # Replace with the path to your input text file\n",
    "output_txt_path = \"cleaned_text_russell.txt\"   # Replace with the desired output file path\n",
    "clean_text_file(input_txt_path, output_txt_path)\n",
    "\n",
    "print(\"Text cleaning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def read_and_process_text_file(file_path):\n",
    "    try:\n",
    "        # Read the text file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            \n",
    "        # Split text into paragraphs using a more specific pattern\n",
    "        # This pattern looks for:\n",
    "        # 1. Paragraphs starting with capital letters after line breaks\n",
    "        # 2. Sections separated by blank lines\n",
    "        # 3. Numbered or bulleted sections\n",
    "        paragraphs = []\n",
    "        current_para = []\n",
    "        \n",
    "        # Split into lines first\n",
    "        lines = text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            # Remove leading/trailing whitespace\n",
    "            line = line.strip()\n",
    "            \n",
    "            # If line is empty and we have collected some text\n",
    "            if not line and current_para:\n",
    "                # Join the collected lines and add to paragraphs\n",
    "                paragraphs.append(' '.join(current_para))\n",
    "                current_para = []\n",
    "            # If line starts with bullet points, numbers, or is a new section\n",
    "            elif line and (line[0].isupper() or \n",
    "                         line[0].isdigit() or \n",
    "                         line.startswith('•') or \n",
    "                         line.startswith('-')):\n",
    "                # If we have a previous paragraph, save it\n",
    "                if current_para:\n",
    "                    paragraphs.append(' '.join(current_para))\n",
    "                    current_para = []\n",
    "                current_para.append(line)\n",
    "            # If it's a continuation line with content\n",
    "            elif line:\n",
    "                current_para.append(line)\n",
    "        \n",
    "        # Add the last paragraph if exists\n",
    "        if current_para:\n",
    "            paragraphs.append(' '.join(current_para))\n",
    "        \n",
    "        # Clean paragraphs\n",
    "        cleaned_paragraphs = []\n",
    "        for para in paragraphs:\n",
    "            # Clean up extra spaces and join lines\n",
    "            cleaned = ' '.join(para.split())\n",
    "            if cleaned and len(cleaned) > 10:  # Minimum length to filter out very short segments\n",
    "                cleaned_paragraphs.append(cleaned)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(cleaned_paragraphs, columns=['paragraph'])\n",
    "        \n",
    "        # Add paragraph number\n",
    "        df['paragraph_number'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # Reorder columns\n",
    "        df = df[['paragraph_number', 'paragraph']]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Usage example\n",
    "file_path = 'cleaned_text.txt'  # Replace with your text file path\n",
    "df = read_and_process_text_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
