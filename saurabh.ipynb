{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PDFTextProcessor import PDFTextProcessor\n",
    "from AnsweringClass import AnsweringClass\n",
    "\n",
    "# Initialize AnsweringClass and set the books directory\n",
    "ans = AnsweringClass()\n",
    "books_dir = \"/home/saurabh/Desktop/Enigmatica /books\"\n",
    "print(os.listdir(books_dir))\n",
    "# Create an empty DataFrame to store data from all books\n",
    "all_books_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over all PDF files in the directory\n",
    "for file_name in os.listdir(books_dir):\n",
    "    print(file_name)\n",
    "    if file_name.endswith(\".pdf\"):  # Process only PDF files\n",
    "        pdf_path = os.path.join(books_dir, file_name)\n",
    "        base_name = os.path.splitext(file_name)[0]  # Get the base name without extension\n",
    "        # Define file paths for output and cleaned text\n",
    "        output_txt_path = \"output_text.txt\"\n",
    "        cleaned_txt_path = \"cleaned_text.txt\"\n",
    "\n",
    "        # Initialize PDFTextProcessor for each book\n",
    "        processor = PDFTextProcessor(\n",
    "            pdf_path=pdf_path,\n",
    "            output_txt_path=output_txt_path,\n",
    "            cleaned_txt_path=cleaned_txt_path\n",
    "        )\n",
    "\n",
    "        # Step 1: Extract and clean text from the PDF\n",
    "        processor.extract_text()\n",
    "        processor.clean_text_file()\n",
    "\n",
    "        # Step 2: Process the cleaned text into paragraphs and create a DataFrame\n",
    "        df = processor.process_text_to_dataframe(cleaned_txt_path, output_csv_path=\"paragraphs.csv\")\n",
    "        \n",
    "        # Step 3: Add embeddings for the paragraphs\n",
    "        df[\"embedding\"] = df[\"paragraph\"].apply(lambda x: ans.get_sentence_embedding(x))\n",
    "\n",
    "        # Add the book source (filename) for tracking\n",
    "        df[\"Source\"] = base_name\n",
    "\n",
    "        # Append the data from this book to the overall DataFrame\n",
    "        all_books_df = pd.concat([all_books_df, df], ignore_index=True)\n",
    "\n",
    "# After processing all books, save the combined DataFrame as a CSV file\n",
    "all_books_df.to_csv(\"all_books_paragraphs.csv\", index=False)\n",
    "\n",
    "# Optionally print or check the combined DataFrame\n",
    "print(\"Combined DataFrame saved to all_books_paragraphs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PDFTextProcessor import PDFTextProcessor\n",
    "from AnsweringClass import AnsweringClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"all_books_paragraphs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.drop('embedding', axis=1)\n",
    "df = df.drop(\"Source\",axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding\"] = df[\"paragraph\"].apply(lambda x: ans.get_sentence_embedding(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = input()\n",
    "\n",
    "# Generate the embedding for the question\n",
    "question_embedding = ans.get_sentence_embedding(question)\n",
    "\n",
    "ansList = ans.get_top_matches(question,df,embedding_column=\"embedding\")\n",
    "answer = \"\"\n",
    "for tup in ansList:\n",
    "    answer = answer+tup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andriy Burkov'sPreface Let’s start by telling the truth: machines don’t learn. What a typical “learning machine” does, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called “training data”), produces the desired outputs. This mathematical formula also generates the correct outputs for most other inputs (distinct from the training data) on the condition that those inputs come from the same or a similar statistical distribution as the one the training data was drawn from.The goal of machine learning is to develop methods that can automatically detect patterns in data, and then to use the uncovered patterns to predict future data or other outcomes of interest. Machine learning is thus closely related to the ﬁelds of statistics and data mining, but differs slightly in terms of its emphasis and terminology.This includes supervised learning techniques that compare known combinations of input and output variables to discern patterns and make predictions, and reinforcement learning which randomly trials a massive number of input variables to produce a desired output. Another machine learning technique, called unsupervised learning, generates predictions based on the analysis of input variables with no known target output.We are also grateful for the members of a book reading club in Jerusalem that have carefully read and constructively criticized every line of vani, Aharon Birnbaum, Alon Cohen, Alon Gonen, Roi Livni, Ofer Meshi, Dan Rosenbaum, Dana Rubinstein, Shahar Somin, Alon Vinnikov, and Yoav Wald. We would also like to thank Gal Elidan, Amir Globerson, Nika Haghtalab, Shie Mannor, Amnon Shashua, Nati Srebro, and Ruth Urner for helpful discussions.Introduction The subject of this book is automated learning, or, as we will more often call it, Machine Learning (ML).A Plain English Introduction Oliver TheobaldThird Edition All rights reserved. No part of this publication may be reproduced, photocopying, recording, or other electronic or mechanical methods, without the prior written permission of the publisher, except in the case of brief quotations embodied in critical reviews and certain other Edited by Jeremy Pedersen and Red to Black Editing’s Christopher For feedback, print quality issues, media contact, omissions or errors regarding this book, please contact the author at oliver.theobald@scatterplotpress.comTABLE OF CONTENTS WHAT IS MACHINE LEARNING?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_books_paragraphs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "\n",
    "# Set up your connection and cursor\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"mydatabase\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Saurabh@1\",\n",
    "    host=\"localhost\",  # or your host\n",
    "    port=\"5432\"        # default PostgreSQL port\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Prepare the data for insertion\n",
    "insert_data = [(text, [embedding.replace(\" \",\",\")]) for text, embedding in zip(df['paragraph'], df['embedding'])]\n",
    "print(insert_data)\n",
    "# # Insert data into PostgreSQL table\n",
    "# insert_query = \"\"\"\n",
    "# INSERT INTO embeddings (text, embedding)\n",
    "# VALUES (%s, %s::vector(384));  -- Assuming vector length is 384, adjust as needed\n",
    "# \"\"\"\n",
    "\n",
    "# execute_values(cursor, insert_query, insert_data)\n",
    "\n",
    "# # Commit the transaction and close the connection\n",
    "# conn.commit()\n",
    "# cursor.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
